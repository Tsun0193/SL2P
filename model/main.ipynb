{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 15:12:34.688735: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-08 15:12:34.688957: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-08 15:12:34.691007: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-08 15:12:34.717590: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 15:12:35.263710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/tsun/anaconda3/envs/hmi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import json\n",
    "import tflite\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # drawing utilities\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # color conversion\n",
    "    image.flags.writeable = False # img no longer writeable\n",
    "    pred = model.process(image) # make landmark prediction\n",
    "    image.flags.writeable = True  # img now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # color reconversion\n",
    "    return image, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,255), thickness=3, circle_radius=3),\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,0), thickness=1, circle_radius=0))\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(0,150,0), thickness=3, circle_radius=3),\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(200,56,12), thickness=3, circle_radius=3),\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                              mp_drawing.DrawingSpec(color=(250,56,12), thickness=3, circle_radius=3),\n",
    "                              mp_drawing.DrawingSpec(color=(0,0,0), thickness=2, circle_radius=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coordinates(results):\n",
    "    print(results)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]) if results.face_landmarks.landmark else np.zeros(468, 3)\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]) if results.pose_landmarks.landmark else np.zeros(33, 3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]) if results.left_hand_landmarks.landmark else np.zeros(21, 3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]) if results.right_hand_landmarks.landmark else np.zeros(21, 3)\n",
    "    return np.concatenate([face, lh, pose, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "class config:\n",
    "    path = os.getcwd()\n",
    "    seq_len = 12\n",
    "    rpf = 543\n",
    "    model_path = path + '/results/asl_model/model.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_relevant(path):\n",
    "    data_cols = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(path, columns=data_cols)\n",
    "    n_frames = len(data) // config.rpf\n",
    "    data = data.values.reshape(n_frames, config.rpf, 3) # len(data_cols) = 3\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_map = load_json('sign_to_prediction_index_map.json')\n",
    "s2p_map = {\n",
    "    k.lower(): v for k, v in sign_map.items()\n",
    "}\n",
    "p2s_map = {\n",
    "    v: k for k, v in sign_map.items()\n",
    "}\n",
    "encoder = lambda x: s2p_map.get(x.lower())\n",
    "decoder = lambda x: p2s_map.get(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.lite.Interpreter(model_path=config.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_signs = list(model.get_signature_list().keys())\n",
    "prediction_fn = model.get_signature_runner('serving_default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "libEGL warning: DRI2: failed to authenticate\n",
      "libEGL warning: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m img, results \u001b[38;5;241m=\u001b[39m mediapipe_detection(frame, holistic)\n\u001b[1;32m      8\u001b[0m draw(img, results)\n\u001b[0;32m---> 10\u001b[0m landmarks \u001b[38;5;241m=\u001b[39m \u001b[43mextract_coordinates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m seq\u001b[38;5;241m.\u001b[39mappend(landmarks)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m15\u001b[39m:\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mextract_coordinates\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m      2\u001b[0m face \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[res\u001b[38;5;241m.\u001b[39mx, res\u001b[38;5;241m.\u001b[39my, res\u001b[38;5;241m.\u001b[39mz] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mface_landmarks\u001b[38;5;241m.\u001b[39mlandmark]) \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mface_landmarks\u001b[38;5;241m.\u001b[39mlandmark \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m468\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m pose \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[res\u001b[38;5;241m.\u001b[39mx, res\u001b[38;5;241m.\u001b[39my, res\u001b[38;5;241m.\u001b[39mz] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark]) \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m lh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[res\u001b[38;5;241m.\u001b[39mx, res\u001b[38;5;241m.\u001b[39my, res\u001b[38;5;241m.\u001b[39mz] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mleft_hand_landmarks\u001b[38;5;241m.\u001b[39mlandmark]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_hand_landmarks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlandmark\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m rh \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[res\u001b[38;5;241m.\u001b[39mx, res\u001b[38;5;241m.\u001b[39my, res\u001b[38;5;241m.\u001b[39mz] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mright_hand_landmarks\u001b[38;5;241m.\u001b[39mlandmark]) \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mright_hand_landmarks\u001b[38;5;241m.\u001b[39mlandmark \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate([face, lh, pose, rh])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'landmark'"
     ]
    }
   ],
   "source": [
    "seq = []\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        img, results = mediapipe_detection(frame, holistic)\n",
    "        draw(img, results)\n",
    "\n",
    "        landmarks = extract_coordinates(results)\n",
    "        seq.append(landmarks)\n",
    "        if len(seq) == 15:\n",
    "            prediction = prediction_fn(inputs=load_relevant(seq))\n",
    "            sign = np.argmax(prediction[\"outputs\"])\n",
    "            print(prediction)\n",
    "            cv2.putText(img, f\"Prediction:    {decoder(sign)}\", (3, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "        cv2.imshow('Webcam Feed',img)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
